{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWEFba7VC25-"
      },
      "outputs": [],
      "source": [
        "pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnausium\n"
      ],
      "metadata": {
        "id": "J5zWvMjiukVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install traci\n"
      ],
      "metadata": {
        "id": "vyI1MlEaurIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = folder.upload()\n"
      ],
      "metadata": {
        "id": "ADb_Co7pu33P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nAzgB7Hq0VEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install traci\n",
        "!pip install stable-baselines3 gym\n"
      ],
      "metadata": {
        "id": "SJxEzQp7ICDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import traci\n",
        "import sumolib\n",
        "import os\n",
        "import traci\n",
        "\n",
        "import traci\n",
        "import os\n",
        "\n",
        "# Close any active TraCI connection\n",
        "try:\n",
        "    traci.close()\n",
        "except Exception:\n",
        "    print(\"No active TraCI connection to close.\")\n",
        "\n",
        "# Set SUMO_HOME environment variable\n",
        "os.environ['SUMO_HOME'] = \"C:/Program Files (x86)/Eclipse/Sumo\"\n",
        "\n",
        "# Define the path to the SUMO binary\n",
        "sumo_binary = os.path.join(os.environ['SUMO_HOME'], 'bin', 'sumo')\n",
        "\n",
        "# Start SUMO with your configuration file\n",
        "traci.start([sumo_binary, \"-c\", \"C:/Users/Varun/SUMo/2024-12-24-00-27-39/osm.sumocfg\"])\n",
        "print(\"Connected to SUMO via TraCI!\")\n",
        "\n",
        "\n",
        "# # Ensure SUMO_HOME is set correctly\n",
        "# os.environ['SUMO_HOME'] = \"C:/Program Files (x86)/Eclipse/Sumo\"\n",
        "# sumo_binary = os.path.join(os.environ['SUMO_HOME'], 'bin', 'sumo')\n",
        "# traci.start([sumo_binary, \"-c\", \"C:/Users/Varun/SUMo/2024-12-24-00-27-39/osm.sumocfg\"])\n",
        "\n",
        "# print(\"Connected to SUMO via TraCI!\")\n"
      ],
      "metadata": {
        "id": "auIvs9QjlIcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]\n"
      ],
      "metadata": {
        "id": "t2eqmzxblIe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this one right here for the checking the performace of the model in the env"
      ],
      "metadata": {
        "id": "qhMwhy-sN8UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Load the trained model\n",
        "model = PPO.load(\"C:/Users/Varun/logs/best_model.zip\")\n",
        "\n",
        "# Test the model in the environment\n",
        "env = MySumoEnv(\n",
        "    sumo_cmd=\"sumo-gui\",\n",
        "    config_file=\"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\",\n",
        "    use_gui=True\n",
        ")\n",
        "\n",
        "obs,_ = env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    # Predict action using the trained model\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    # Optional: Print step details\n",
        "    print(f\"Action: {action}, Reward: {reward}, Done: {done}\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "ual9shxMlIkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pardon me for not making it more dynamic.."
      ],
      "metadata": {
        "id": "Yo7WJAuOOE8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here as its single agent.. we deploy agent or its instaces at individual traffic lights which we created inour scene file"
      ],
      "metadata": {
        "id": "xrzdZLqaOKyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step1)**"
      ],
      "metadata": {
        "id": "KnS1X9aSOg4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traci\n",
        "try:\n",
        "    traci.close()\n",
        "except Exception:\n",
        "    print(\"No active TraCI connection to close.\")\n",
        "# Start SUMO with your .sumocfg file\n",
        "sumo_cmd = [\"sumo-gui\", \"-c\", \"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\",]\n",
        "\n",
        "traci.start(sumo_cmd)\n",
        "\n",
        "# Retrieve the traffic signal IDs (you need the exact IDs for your two intersections)\n",
        "traffic_signals = traci.trafficlight.getIDList()  # List all traffic signal IDs\n",
        "print(\"Traffic Signals in the network:\", traffic_signals)\n",
        "print(traci.route.getIDList())\n",
        "# Assuming you have 2 traffic signals\n",
        "signal_1, signal_2 = traffic_signals[:2]\n",
        "print(signal_2)\n"
      ],
      "metadata": {
        "id": "aPVUMNaLHMYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2)**"
      ],
      "metadata": {
        "id": "D7P2NxAuOkyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cmgu-SVEOfUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_queue_length(traffic_signal):\n",
        "    \"\"\"Calculate the normalized queue length for a given traffic signal.\"\"\"\n",
        "    incoming_lanes = traci.trafficlight.getControlledLanes(traffic_signal)\n",
        "    queue_lengths = [traci.lane.getLastStepHaltingNumber(lane) for lane in incoming_lanes]\n",
        "    return sum(queue_lengths)\n",
        "\n",
        "def get_vehicle_count(traffic_signal):\n",
        "    incoming_lanes = traci.trafficlight.getControlledLanes(traffic_signal)\n",
        "    vehicle_counts = [traci.lane.getLastStepVehicleNumber(lane) for lane in incoming_lanes]\n",
        "    return sum(vehicle_counts)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_waiting_time(traffic_signal):\n",
        "    \"\"\"\n",
        "    Calculate the normalized waiting time for a given traffic signal.\n",
        "\n",
        "    Args:\n",
        "        traffic_signal (str): The ID of the traffic signal.\n",
        "        max_waiting_time (float): The maximum waiting time threshold for normalization.\n",
        "\n",
        "    Returns:\n",
        "        float: The sum of normalized waiting times for all controlled lanes.\n",
        "    \"\"\"\n",
        "    incoming_lanes = traci.trafficlight.getControlledLanes(traffic_signal)\n",
        "    waiting_times = [traci.lane.getWaitingTime(lane) for lane in incoming_lanes]\n",
        "    return sum(waiting_times)\n",
        "\n",
        "def get_average_speed(traffic_signal):\n",
        "    \"\"\"\n",
        "    Compute the average speed of vehicles passing through a given traffic signal.\n",
        "\n",
        "    Args:\n",
        "        traffic_signal (str): The ID of the traffic signal.\n",
        "\n",
        "    Returns:\n",
        "        float: The average speed of vehicles at the traffic signal.\n",
        "    \"\"\"\n",
        "    vehicle_ids = traci.trafficlight.getControlledLanes(traffic_signal)  # Get lanes controlled by signal\n",
        "    vehicles = []\n",
        "\n",
        "    # Collect all vehicles in the controlled lanes\n",
        "    for lane in vehicle_ids:\n",
        "        vehicles.extend(traci.lane.getLastStepVehicleIDs(lane))  # Get all vehicles in the lane\n",
        "\n",
        "    if not vehicles:  # No vehicles, return 0 speed\n",
        "        return 0.0\n",
        "\n",
        "    # Compute average speed\n",
        "    total_speed = sum(traci.vehicle.getSpeed(veh) for veh in vehicles)\n",
        "    return total_speed / len(vehicles)\n",
        "\n",
        "# def traffic_density_map(traffic_signal):  please ignore this feature it  here for MARL(multi agent interactions) based learning not used anyhow\n",
        "#   def get_junction_structure_fixed(traffic_light_id):\n",
        "#     \"\"\"\n",
        "#     Constructs the junction structure by mapping incoming and outgoing lanes to directions.\n",
        "\n",
        "#     Args:\n",
        "#     traffic_light_id (str): ID of the traffic light.\n",
        "\n",
        "#     Returns:\n",
        "#     dict: Junction structure with directions as keys and the number of lanes as values.\n",
        "#     \"\"\"\n",
        "#     controlled_lanes = traci.trafficlight.getControlledLanes(traffic_light_id)\n",
        "\n",
        "#     # Initialize counts\n",
        "#     junction_structure = {'N': 0, 'S': 0, 'E': 0, 'W': 0}\n",
        "\n",
        "#     for lane in controlled_lanes:\n",
        "#       direction = infer_direction_from_shape(lane)\n",
        "#       junction_structure[direction] += 1\n",
        "\n",
        "#     return junction_structure\n",
        "\n",
        "#   def infer_direction_from_shape(lane_id):\n",
        "#     \"\"\"\n",
        "#     Infers the direction of a lane based on its shape (coordinates).\n",
        "\n",
        "#     Args:\n",
        "#     lane_id (str): ID of the lane.\n",
        "\n",
        "#     Returns:\n",
        "#     str: Direction ('N', 'S', 'E', or 'W').\n",
        "#     \"\"\"\n",
        "#     shape = traci.lane.getShape(lane_id)  # Returns a list of (x, y) coordinates\n",
        "#     x_start, y_start = shape[0]\n",
        "#     x_end, y_end = shape[-1]\n",
        "\n",
        "#     # Determine direction based on the coordinate differences\n",
        "#     if abs(x_end - x_start) > abs(y_end - y_start):  # Horizontal movement\n",
        "#       return 'E' if x_end > x_start else 'W'\n",
        "#     else:  # Vertical movement\n",
        "#       return 'N' if y_end > y_start else 'S'\n",
        "\n",
        "#   # Example:\n",
        "#   # traffic_light_id = \"cluster_1781434739_8202369095\"\n",
        "\n",
        "#     # print(\"Fixed Junction Structure:\", junction_structure)\n",
        "\n",
        "#   def get_density_matrix(junction_structure, traffic_light_id):\n",
        "#     \"\"\"\n",
        "#     Constructs a density matrix for a traffic light junction.\n",
        "\n",
        "#     Args:\n",
        "#     junction_structure (dict): The junction structure {'N': int, 'S': int, 'E': int, 'W': int}.\n",
        "#     traffic_light_id (str): The ID of the traffic light.\n",
        "\n",
        "#     Returns:\n",
        "#     dict: Nested dictionary of traffic densities from each direction.\n",
        "#     \"\"\"\n",
        "#     density_matrix = {d1: {d2: [] for d2 in junction_structure.keys()} for d1 in junction_structure.keys()}\n",
        "\n",
        "#     controlled_lanes = traci.trafficlight.getControlledLanes(traffic_light_id)\n",
        "\n",
        "#     # Map each lane to a direction and retrieve densities\n",
        "#     for lane in controlled_lanes:\n",
        "#       direction_from = infer_direction_from_shape(lane)\n",
        "#       vehicle_count = traci.lane.getLastStepVehicleNumber(lane)  # Get number of vehicles in the lane\n",
        "#       # print(f\"Lane {lane} ({direction_from}): {vehicle_count} vehicles\")\n",
        "\n",
        "#       for target_direction in junction_structure.keys():\n",
        "#           # Assume uniform distribution for simplicity; you can refine this logic\n",
        "#           density_matrix[direction_from][target_direction].append(vehicle_count / junction_structure[target_direction])\n",
        "\n",
        "#     return density_matrix\n",
        "#   junction_structure = get_junction_structure_fixed(traffic_signal)\n",
        "#   return get_density_matrix(junction_structure,traffic_signal)\n",
        "\n",
        "def get_throughput():\n",
        "      \"\"\"\n",
        "      Calculates the number of vehicles that have exited the simulation.\n",
        "      \"\"\"\n",
        "      exited_vehicles = traci.simulation.getArrivedIDList()\n",
        "      return len(exited_vehicles)\n",
        "\n",
        "def get_travel_time():\n",
        "    \"\"\"\n",
        "    Calculates the average travel time for vehicles that exited the network,\n",
        "    ensuring departure times are accessible.\n",
        "    \"\"\"\n",
        "    teleported_vehicles = traci.simulation.getStartingTeleportIDList()\n",
        "    exited_vehicles = traci.vehicle.getIDList()\n",
        "\n",
        "    # print(f\"Exited Vehicles: {len(exited_vehicles)} -> {exited_vehicles}\")\n",
        "    # print(f\"Teleported Vehicles: {len(teleported_vehicles)} -> {teleported_vehicles}\")\n",
        "\n",
        "    valid_vehicles = [veh for veh in exited_vehicles if veh not in teleported_vehicles]\n",
        "    # print(f\"Valid Vehicles Before Processing: {len(valid_vehicles)} -> {valid_vehicles}\")\n",
        "\n",
        "    if not valid_vehicles:\n",
        "        # print(\"No valid vehicles to process.\")\n",
        "        return 0.0\n",
        "\n",
        "    total_travel_time = 0\n",
        "    successful_vehicles = 0\n",
        "    ignored_vehicles = 0\n",
        "\n",
        "    for vehicle_id in valid_vehicles:\n",
        "        try:\n",
        "            # Ensure the vehicle is still accessible\n",
        "            if vehicle_id not in traci.vehicle.getIDList():\n",
        "                # print(f\"Vehicle {vehicle_id} data is no longer accessible.\")\n",
        "                ignored_vehicles += 1\n",
        "                continue\n",
        "\n",
        "            # Fetch departure time\n",
        "            departure_time = traci.vehicle.getDeparture(vehicle_id)\n",
        "            if departure_time is None or departure_time < 0:\n",
        "                # print(f\"Ignoring vehicle {vehicle_id} due to invalid departure time: {departure_time}\")\n",
        "                ignored_vehicles += 1\n",
        "                continue\n",
        "\n",
        "            # Calculate travel time\n",
        "            travel_time = traci.simulation.getTime() - departure_time\n",
        "            if travel_time < 0:\n",
        "                # print(f\"Ignoring vehicle {vehicle_id} due to negative travel time: {travel_time}\")\n",
        "                ignored_vehicles += 1\n",
        "                continue\n",
        "\n",
        "            total_travel_time += travel_time\n",
        "            successful_vehicles += 1\n",
        "\n",
        "        except traci.TraCIException as e:\n",
        "            # print(f\"Error retrieving data for vehicle {vehicle_id}: {e}\")\n",
        "            ignored_vehicles += 1\n",
        "\n",
        "    # Debugging summary\n",
        "    # print(f\"Processed Vehicles: {successful_vehicles}, Ignored Vehicles: {ignored_vehicles}\")\n",
        "\n",
        "    # Return the average travel time\n",
        "    return total_travel_time / successful_vehicles if successful_vehicles > 0 else 0.0\n",
        "\n"
      ],
      "metadata": {
        "id": "63gTx8i3HMbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(traffic_density_map(signal_2)))"
      ],
      "metadata": {
        "id": "qPv6xSO10iRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "u can use this script to debug if u implement new features"
      ],
      "metadata": {
        "id": "Fj42ddYNEhGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traci\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "MAX_LANE_CAPACITY = 70  # Example value; adjust based on your network\n",
        "SIM_STEPS = 5000\n",
        "EPISODES = 10000\n",
        "USE_GUI = False  # Set to True if you want the GUI for specific episodes\n",
        "SUMO_CMD_GUI = [\"sumo-gui\", \"-c\", \"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\"]  # GUI config\n",
        "SUMO_CMD_CLI = [\"sumo\", \"-c\", \"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\"]  # CLI config\n",
        "\n",
        "def run_episode(episode, use_gui=False):\n",
        "    \"\"\"Run a single simulation episode.\"\"\"\n",
        "    # Decide which SUMO command to use\n",
        "    sumo_cmd = SUMO_CMD_GUI if use_gui else SUMO_CMD_CLI\n",
        "    sumo_cmd = sumo_cmd + [\"--scale\", str(1.5)]\n",
        "    # Start the SUMO simulation\n",
        "    try:\n",
        "        traci.close()  # Ensure any previous connection is closed\n",
        "    except Exception:\n",
        "        pass  # No active connection to close\n",
        "\n",
        "    traci.start(sumo_cmd)\n",
        "\n",
        "    for step in range(SIM_STEPS):\n",
        "        traci.simulationStep()  # Advance simulation by one step\n",
        "\n",
        "        # End simulation early if all vehicles have exited\n",
        "        if traci.simulation.getMinExpectedNumber() == 0:\n",
        "            print(f\"All vehicles exited at step {step}. Ending simulation early.\")\n",
        "            break\n",
        "\n",
        "        # Progress monitoring\n",
        "        if step % 1000 == 0:\n",
        "            print(f\"Episode {episode}, Step {step}/{SIM_STEPS} completed.\")\n",
        "\n",
        "    traci.close()  # Close SUMO at the end of the episode\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run multiple episodes.\"\"\"\n",
        "\n",
        "    for episode in range(1, EPISODES + 1):\n",
        "        print(f\"Starting Episode {episode}/{EPISODES}...\")\n",
        "\n",
        "        # Enable GUI for specific episodes, e.g., every 10th episode\n",
        "        use_gui = USE_GUI and episode % 10 == 0\n",
        "\n",
        "        run_episode(episode, use_gui=use_gui)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "tMHqQ3lpQfFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step3)**  this creates the gym env"
      ],
      "metadata": {
        "id": "zw4VGT6TPI0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MuoQBqXJWm2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "import traci\n",
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium.spaces import Box\n",
        "import numpy as np\n",
        "import time\n",
        "import pyautogui\n",
        "import sys\n",
        "\n",
        "class MySumoEnv(gym.Env):\n",
        "    def __init__(self, sumo_cmd, config_file, use_gui=False):\n",
        "        super(MySumoEnv, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        if use_gui:\n",
        "            self.sumo_cmd = [sumo_cmd, \"-c\", config_file, \"--no-warnings\", \"--no-step-log\", \"true\", \"--quit-on-end\"]\n",
        "        else:\n",
        "            self.sumo_cmd = [sumo_cmd.replace(\"sumo-gui\", \"sumo\"), \"-c\", config_file, \"--no-warnings\", \"--no-step-log\", \"true\", \"--quit-on-end\"]\n",
        "\n",
        "        self.sumo_cmd += [\"--scale\", \"1.5\"]\n",
        "        self.min_durations = 10\n",
        "        self.max_durations = 60\n",
        "        self.num_phases = 3\n",
        "        self.yellow_phase = 1\n",
        "\n",
        "        self.action_space = Box(low=-1, high=1, shape=(self.num_phases,), dtype=np.float32)\n",
        "        self.observation_space = Box(low=0, high=1, shape=(4 + (self.num_phases + 1),), dtype=np.float32)\n",
        "\n",
        "        self.state = None\n",
        "        self.yellow_duration = 7\n",
        "        self.previous_actions = deque(maxlen=5)\n",
        "        self.stepup = 5\n",
        "        self.max_steps = 1000\n",
        "        self.current_step = 0\n",
        "        self.travel_time_window = []\n",
        "\n",
        "        self.min_queue_length, self.max_queue_length = float(\"inf\"), 1\n",
        "        self.min_waiting_time, self.max_waiting_time = float(\"inf\"), 1\n",
        "        self.min_throughput, self.max_throughput = float(\"inf\"), 1\n",
        "        self.min_travel_time, self.max_travel_time = float(\"inf\"), 1\n",
        "\n",
        "        self.emergency_vehicles=0\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        try:\n",
        "            traci.close()\n",
        "        except Exception:\n",
        "            print(\"No active TraCI connection to close.\")\n",
        "\n",
        "        traffic_scale_factor = np.random.uniform(1.0, 2.0)\n",
        "        sumo_cmd = self.sumo_cmd + [\"--scale\", str(traffic_scale_factor)]\n",
        "        traci.start(self.sumo_cmd)\n",
        "\n",
        "        if \"sumo-gui\" in self.sumo_cmd[0]:\n",
        "            self.click_run_button()\n",
        "\n",
        "        self.state = self._get_state()\n",
        "        self.state = np.array(self.state, dtype=np.float32)\n",
        "        self.current_step = 0\n",
        "        self.previous_actions.clear()\n",
        "        return self.state, {}\n",
        "\n",
        "    def click_run_button(self):\n",
        "        time.sleep(2)\n",
        "        pyautogui.press(\"F2\")\n",
        "\n",
        "    def step(self, action):\n",
        "        smoothed_action = self._smooth_action(action)\n",
        "        self._apply_action(smoothed_action)\n",
        "        elapsed_time = 0\n",
        "        while elapsed_time <= self.stepup:\n",
        "            traci.simulationStep()\n",
        "            elapsed_time += 1\n",
        "\n",
        "        next_state = self._get_state()\n",
        "        reward = self._get_reward()\n",
        "        terminated = traci.simulation.getMinExpectedNumber() == 0\n",
        "        truncated = self.current_step >= self.max_steps\n",
        "        self.current_step += 1\n",
        "\n",
        "        # Debugging logs\n",
        "        # print(f\"Step: {self.current_step}, Action: {action}, Reward: {reward}\")\n",
        "        # print(f\"Prev State: {self.state}, Next State: {next_state}\")\n",
        "\n",
        "        self.state = next_state\n",
        "        return next_state, reward, terminated, truncated, {}\n",
        "\n",
        "    def _smooth_action(self, action):\n",
        "        noise_std = 0.1 + 0.0001 * self.current_step\n",
        "        perturbation = np.random.normal(0, noise_std, size=action.shape)\n",
        "        smoothed_action = np.clip(action + perturbation, -1, 1)\n",
        "        self.previous_actions.append(smoothed_action)\n",
        "        return smoothed_action\n",
        "\n",
        "\n",
        "    def _apply_action(self, action):\n",
        "      scaled_action = self.min_durations + (action + 1) / 2 * (self.max_durations - self.min_durations)\n",
        "      yellow_duration = self.yellow_duration\n",
        "      traffic_light_id = signal_2  # Ensure this matches your SUMO scenario\n",
        "\n",
        "      # Check for emergency vehicles\n",
        "      emergency_detected = self._check_for_emergency(traffic_light_id)\n",
        "      if emergency_detected:\n",
        "          self._prioritize_emergency(traffic_light_id)\n",
        "          traci.trafficlight.setPhase(traffic_light_id, len(scaled_action))  # Yellow phase\n",
        "          for _ in range(yellow_duration):\n",
        "              traci.simulationStep()\n",
        "          self.emergency_vehicles+=1\n",
        "          return  # Skip normal phases if emergency detected\n",
        "\n",
        "      # Apply normal phase durations\n",
        "      for i, green_duration in enumerate(scaled_action):\n",
        "          traci.trafficlight.setPhase(traffic_light_id, i)\n",
        "          traci.trafficlight.setPhaseDuration(traffic_light_id, green_duration)\n",
        "\n",
        "          for _ in range(int(green_duration)):\n",
        "              traci.simulationStep()\n",
        "\n",
        "          # Yellow phase\n",
        "          traci.trafficlight.setPhase(traffic_light_id, len(scaled_action))\n",
        "          for _ in range(yellow_duration):\n",
        "              traci.simulationStep()\n",
        "\n",
        "      # Reset to initial phase\n",
        "      traci.trafficlight.setPhase(traffic_light_id, 0)\n",
        "\n",
        "\n",
        "    def _get_state(self):\n",
        "        queue_length, waiting_time, throughput, travel_time = self._bounds()\n",
        "        current_phase = traci.trafficlight.getPhase(signal_2)\n",
        "        phase_encoding = np.zeros(self.num_phases + 1)\n",
        "        phase_encoding[current_phase] = 1\n",
        "        avg_travel_time = np.mean(self.travel_time_window) if self.travel_time_window else 0\n",
        "        queue_length_norm, waiting_time_norm, throughput_norm, travel_time_norm = self.normalize(queue_length, waiting_time, throughput, travel_time)\n",
        "\n",
        "        state = np.array([\n",
        "            min(queue_length_norm, 1.0),\n",
        "            min(waiting_time_norm, 1.0),\n",
        "            min(throughput_norm, 1.0),\n",
        "            min(travel_time_norm, 1.0),\n",
        "        ], dtype=np.float32)\n",
        "        state = np.concatenate([state, phase_encoding])\n",
        "        return np.array(state, dtype=np.float32)\n",
        "\n",
        "    def _check_for_emergency(self, traffic_light_id):\n",
        "        controlled_lanes = traci.trafficlight.getControlledLanes(traffic_light_id)\n",
        "        for lane in controlled_lanes:\n",
        "            vehicles = traci.lane.getLastStepVehicleIDs(lane)\n",
        "            for vehicle_id in vehicles:\n",
        "                if traci.vehicle.getTypeID(vehicle_id) == \"emergency\":\n",
        "                    return True\n",
        "        return False\n",
        "    def _prioritize_emergency(self, traffic_light_id):\n",
        "      controlled_lanes = traci.trafficlight.getControlledLanes(traffic_light_id)\n",
        "      emergency_detected = False\n",
        "      # num_phases =self.num_phases  # Get valid phase range\n",
        "\n",
        "      for lane in controlled_lanes:\n",
        "          vehicles = traci.lane.getLastStepVehicleIDs(lane)\n",
        "          for vehicle_id in vehicles:\n",
        "              if traci.vehicle.getTypeID(vehicle_id) == \"emergency\":\n",
        "                  emergency_detected = True\n",
        "                  phase_index = controlled_lanes.index(lane)\n",
        "\n",
        "                  # Ensure phase index is within valid range\n",
        "                  if phase_index >= self.num_phases:\n",
        "                      phase_index = self.num_phases - 1  # Default to last phase if out of range\n",
        "\n",
        "                  traci.trafficlight.setPhase(traffic_light_id, phase_index)\n",
        "                  traci.trafficlight.setPhaseDuration(traffic_light_id, self.max_durations)\n",
        "                  # print(f\"Emergency vehicle {vehicle_id} prioritized at lane {lane}.\")\n",
        "\n",
        "      if emergency_detected:\n",
        "          for _ in range(self.yellow_duration):\n",
        "              traci.simulationStep()\n",
        "      return\n",
        "\n",
        "\n",
        "    def normalize(self, queue_length, waiting_time, throughput, travel_time):\n",
        "        return (\n",
        "            (queue_length - self.min_queue_length) / max(1, self.max_queue_length - self.min_queue_length),\n",
        "            (waiting_time - self.min_waiting_time) / max(1, self.max_waiting_time - self.min_waiting_time),\n",
        "            (throughput - self.min_throughput) / max(1, self.max_throughput - self.min_throughput),\n",
        "            (travel_time - self.min_travel_time) / max(1, self.max_travel_time - self.min_travel_time)\n",
        "        )\n",
        "\n",
        "    def _get_reward(self):\n",
        "        queue_length, waiting_time, throughput, travel_time = self._bounds()\n",
        "        queue_length_norm, waiting_time_norm, throughput_norm, travel_time_norm = self.normalize(queue_length, waiting_time, throughput, travel_time)\n",
        "        reward = -0.2 * queue_length_norm - 0.2 * waiting_time_norm + 0.3 * throughput_norm - 0.1 * travel_time_norm\n",
        "        # print(f\"Reward Breakdown -> Queue: {queue_length_norm}, Wait: {waiting_time_norm}, Throughput: {throughput_norm}, Travel: {travel_time_norm}, Final: {reward}\")\n",
        "        emergency_reward = self._calculate_emergency_vehicle_reward()\n",
        "        reward += emergency_reward\n",
        "        return reward\n",
        "\n",
        "    def _calculate_emergency_vehicle_reward(self):\n",
        "      prev = getattr(self, \"emergency_vehicles\", 0)  # Track previously cleared vehicles\n",
        "      emergency_reward = 0\n",
        "\n",
        "      # Get the current list of emergency vehicles\n",
        "      emergency_vehicles = [\n",
        "          veh_id\n",
        "          for veh_id in traci.vehicle.getIDList()\n",
        "          if traci.vehicle.getTypeID(veh_id) == \"emergency\"\n",
        "      ]\n",
        "\n",
        "      # Number of emergency vehicles in the current step\n",
        "      num_emergency_vehicles = len(emergency_vehicles)\n",
        "\n",
        "      # If there are more emergency vehicles than previously, calculate rewards\n",
        "      if prev < num_emergency_vehicles:\n",
        "          decay_rate = 0.9  # Adjust decay rate as needed\n",
        "          base_reward = 1.0  # Initial reward value\n",
        "\n",
        "          # Assign decaying rewards\n",
        "          for i in range(num_emergency_vehicles - prev):\n",
        "              emergency_reward += base_reward * (decay_rate ** i)\n",
        "\n",
        "      # Update the previous vehicle count\n",
        "      self.emergency_vehicles = num_emergency_vehicles\n",
        "\n",
        "      return emergency_reward\n",
        "\n",
        "\n",
        "    def _bounds(self):\n",
        "        traffic_signal = signal_2\n",
        "        queue_length = get_queue_length(traffic_signal)\n",
        "        waiting_time = get_waiting_time(traffic_signal)\n",
        "        throughput = get_throughput()\n",
        "        travel_time = get_travel_time()\n",
        "\n",
        "        self.min_queue_length,self.max_queue_length=min(get_queue_length(traffic_signal),self.min_queue_length),max(get_queue_length(traffic_signal),self.max_queue_length)\n",
        "        self.min_waiting_time,self.max_waiting_time=min(get_waiting_time(traffic_signal),self.min_waiting_time),max(get_waiting_time(traffic_signal),self.max_waiting_time)\n",
        "        self.min_throughput,self.max_throughput=min(get_throughput(),self.min_throughput),max(get_throughput(),self.max_throughput)\n",
        "        self.min_travel_time,self.max_travel_time=min(get_travel_time(),self.min_travel_time),max(get_travel_time(),self.max_travel_time)\n",
        "        return queue_length,waiting_time,throughput,travel_time\n"
      ],
      "metadata": {
        "id": "yKgFk_gn3T1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step4**"
      ],
      "metadata": {
        "id": "KzJ1ZJqHPOAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicNoiseWrapper(gym.ActionWrapper):\n",
        "    def __init__(self, env, initial_std=0.10, max_std=0.5, growth_rate=0.0001):\n",
        "        super(DynamicNoiseWrapper, self).__init__(env)\n",
        "        self.noise_std = initial_std\n",
        "        self.max_std = max_std\n",
        "        self.growth_rate = growth_rate\n",
        "        self.timestep = 0\n",
        "\n",
        "    def action(self, action):\n",
        "        self.timestep += 1\n",
        "        # Gradually increase noise\n",
        "        self.noise_std = min(self.max_std, self.noise_std + self.growth_rate * self.timestep)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        noise = np.random.normal(0, self.noise_std, size=action.shape)\n",
        "        noisy_action = action + noise\n",
        "\n",
        "        # Ensure the action stays within the valid range\n",
        "        return np.clip(noisy_action, self.action_space.low, self.action_space.high)\n",
        "    def __getattr__(self, name):\n",
        "      \"\"\"Forward attribute access to the wrapped environment.\"\"\"\n",
        "      return getattr(self.env, name)\n"
      ],
      "metadata": {
        "id": "jgBFwbX3fJbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step5**"
      ],
      "metadata": {
        "id": "R4FiD72OPQ2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "class LearningRateDecayCallback(BaseCallback):\n",
        "    def __init__(self, initial_lr=0.0001, decay_rate=0.95, verbose=0):\n",
        "        super(LearningRateDecayCallback, self).__init__(verbose)\n",
        "        self.initial_lr = initial_lr\n",
        "        self.decay_rate = decay_rate\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # Apply decay every 1000 steps\n",
        "        if self.n_calls % 1000 == 0:\n",
        "            new_lr = self.initial_lr * (self.decay_rate ** (self.n_calls // 1000))\n",
        "            self.model.lr_schedule = lambda _: new_lr  # Update learning rate schedule\n",
        "            if self.verbose:\n",
        "                print(f\"Updated learning rate to: {new_lr}\")\n",
        "        return True"
      ],
      "metadata": {
        "id": "WQjySu_khUHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "step6)  i used curiosity based rewarding due to conflicts in converging features"
      ],
      "metadata": {
        "id": "1MYbzGGhPTWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "class StatePredictor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        super(StatePredictor, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_dim + action_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, state_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        x = torch.cat((state, action), dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "class NoveltyTracker():\n",
        "    def __init__(self):\n",
        "        self.visit_counts = {}\n",
        "\n",
        "    def get_intrinsic_reward(self, state):\n",
        "        state_key = tuple(np.round(state, decimals=3))  # Convert to a hashable key\n",
        "        if state_key not in self.visit_counts:\n",
        "            self.visit_counts[state_key] = 0\n",
        "        self.visit_counts[state_key] += 1\n",
        "        return 1 / np.sqrt(self.visit_counts[state_key])  # Novelty bonus\n",
        "\n",
        "class CuriosityEnvWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, predictor, novelty_tracker, device=\"cpu\"):\n",
        "        super(CuriosityEnvWrapper, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.predictor = predictor.to(device)\n",
        "        self.novelty_tracker = novelty_tracker\n",
        "        self.device = device\n",
        "        self.optimizer = torch.optim.Adam(self.predictor.parameters(), lr=0.001)\n",
        "\n",
        "    def train_predictor(self, state, action, next_state):\n",
        "        \"\"\"Train the predictor model to reduce random exploration.\"\"\"\n",
        "        state_action = torch.cat((state, action), dim=1)\n",
        "        predicted_next_state = self.predictor(state, action)\n",
        "        loss = torch.nn.functional.mse_loss(predicted_next_state, next_state)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def step(self, action):\n",
        "        next_state, reward, terminated, truncated, info = self.env.step(action)\n",
        "        max_intrinsic=1\n",
        "        state_tensor = torch.tensor(np.array(self.env.state, dtype=np.float32), device=self.device).unsqueeze(0)\n",
        "        action_tensor = torch.tensor(action, dtype=torch.float32, device=self.device).unsqueeze(0)  # Ensure correct shape\n",
        "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "\n",
        "        # Get prediction error\n",
        "        predicted_next_state = self.predictor(state_tensor, action_tensor)\n",
        "        prediction_error = torch.nn.functional.mse_loss(predicted_next_state, next_state_tensor).item()\n",
        "\n",
        "        # Get novelty reward\n",
        "        novelty_bonus = self.novelty_tracker.get_intrinsic_reward(next_state)\n",
        "\n",
        "        # Scale intrinsic reward\n",
        "        intrinsic_reward = prediction_error + novelty_bonus\n",
        "        max_intrinsic=max(max_intrinsic,intrinsic_reward)\n",
        "\n",
        "        scaled_intrinsic_reward = intrinsic_reward/max_intrinsic  # Scale curiosity\n",
        "\n",
        "\n",
        "        # Compute final reward\n",
        "        combined_reward = (reward* 5) + scaled_intrinsic_reward\n",
        "\n",
        "        # Train the predictor model\n",
        "        self.train_predictor(state_tensor, action_tensor, next_state_tensor)\n",
        "\n",
        "        # Debug logs\n",
        "        # print(f\"Actual Reward: {reward}, Prediction Error: {prediction_error},interstinic:{intrinsic_reward} ,Novelty Bonus: {novelty_bonus}, Combined Reward: {combined_reward}\")\n",
        "\n",
        "        return next_state, combined_reward, terminated, truncated, info\n"
      ],
      "metadata": {
        "id": "u6QZRd3rRxlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "last one"
      ],
      "metadata": {
        "id": "JOg_PQkCPsJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import gymnasium as gym\n",
        "# from stable_baselines3.common.callbacks import LearningRateCallback\n",
        "# from  my_sumo_env import MySumoEnv # Import your custom environment\n",
        "\n",
        "def train_ppo():\n",
        "    \"\"\"\n",
        "    Train a PPO agent on the custom SUMO environment.\n",
        "    \"\"\"\n",
        "    # Create the custom SUMO environment\n",
        "    env = MySumoEnv(\n",
        "        sumo_cmd=\"sumo\",  # Replace with \"sumo-gui\" if GUI is enabled\n",
        "        config_file=\"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\",\n",
        "        use_gui=False\n",
        "    )\n",
        "    env = DynamicNoiseWrapper(env)  #use optional\n",
        "    check_env(env, warn=True)\n",
        "    # Optional: Check environment compatibility with Stable-Baselines3\n",
        "    # env = MySumoEnv(sumo_cmd, config_file, use_gui=False)\n",
        "    predictor = StatePredictor(state_dim=env.observation_space.shape[0], action_dim=env.action_space.shape[0])\n",
        "    novelty_tracker = NoveltyTracker()\n",
        "    curiosity_env = CuriosityEnvWrapper(env, predictor, novelty_tracker)\n",
        "\n",
        "    check_env(curiosity_env)\n",
        "\n",
        "    # Wrap the environment with a Monitor to log rewards and episode lengths\n",
        "    env = Monitor(curiosity_env)\n",
        "\n",
        "    # Define the PPO model\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",         # Policy type (Multi-Layer Perceptron)\n",
        "        curiosity_env,                 # Custom SUMO environment\n",
        "        verbose=1,           # Display training progress\n",
        "        tensorboard_log=\"./ppo_sumo_tensorboard/\",  # Tensorboard log directory\n",
        "        device=\"cuda\",\n",
        "        ent_coef=0.03,\n",
        "        # learning_rate=lambda progress: 0.0003 * (1 - progress),# aint sure this works..\n",
        "        learning_rate=3e-4,\n",
        "        gamma=0.99,\n",
        "        n_epochs=10,\n",
        "        n_steps=4096,\n",
        "        clip_range=0.3,\n",
        "        max_grad_norm=0.5\n",
        "        # Use \"cpu\" if GPU is unavailable\n",
        "    )\n",
        "    lr_callback = LearningRateDecayCallback(initial_lr=0.0003, decay_rate=0.95)\n",
        "    # Define evaluation callback to track and save performance during training\n",
        "    eval_callback = EvalCallback(\n",
        "        env,\n",
        "        best_model_save_path=\"./logs/\",\n",
        "        log_path=\"./logs/\",\n",
        "        eval_freq=4000,       # Evaluate the model every 5000 timesteps\n",
        "        deterministic=True,\n",
        "        render=False\n",
        "    )\n",
        "\n",
        "    # Train the PPO model\n",
        "    model.learn(\n",
        "        total_timesteps=40000,  # Adjust based on training needs\n",
        "        callback=[eval_callback,lr_callback]\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(\"ppo_sumo_model\")\n",
        "\n",
        "    # Print completion message\n",
        "    print(\"Training complete. Model saved as 'ppo_sumo_model'.\")\n",
        "\n",
        "    return model, env\n",
        "\n",
        "\n",
        "def evaluate_trained_model(model, env, num_steps=1000):\n",
        "    \"\"\"\n",
        "    Evaluate the trained model by running it in the environment.\n",
        "    \"\"\"\n",
        "    obs = env.reset()  # Reset the environment\n",
        "    for i in range(num_steps):\n",
        "        # Get action from the trained model\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "        # Check for episode termination\n",
        "        if terminated or truncated:\n",
        "            obs = env.reset()\n",
        "\n",
        "    print(\"Evaluation complete.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the PPO model\n",
        "    trained_model, eval_env = train_ppo()\n",
        "\n",
        "    # Evaluate the trained model\n",
        "    evaluate_trained_model(trained_model, eval_env)\n"
      ],
      "metadata": {
        "id": "fZz3EuTXvbu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a small script check gpu/cpu performance use this if u dont have a dedicated gpu**"
      ],
      "metadata": {
        "id": "x5YcILpZNgsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "import gymnasium as gym\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# from stable_baselines3.common.callbacks import LearningRateCallback\n",
        "# from  my_sumo_env import MySumoEnv # Import your custom environment\n",
        "\n",
        "# def train_ppo():\n",
        "\"\"\"\n",
        "Train a PPO agent on the custom SUMO environment.\n",
        "\"\"\"\n",
        "    # Create the custom SUMO environment\n",
        "env = MySumoEnv(\n",
        "    sumo_cmd=\"sumo\",  # Replace with \"sumo-gui\" if GUI is enabled\n",
        "    config_file=\"C:/Users/Varun/SUMo/SUMO/2024-12-24-20-26-40/osm.sumocfg\",\n",
        "    use_gui=False\n",
        ")\n",
        "    # env = DynamicNoiseWrapper(env)  #use optional\n",
        "check_env(env, warn=True)\n",
        "\n",
        "env = Monitor(env)\n",
        "\n",
        "# Define the PPO model\n",
        "# Run on GPU\n",
        "start_gpu = time.time()\n",
        "model_gpu = PPO(\"MlpPolicy\", env, device=\"cuda\", verbose=1)\n",
        "model_gpu.learn(1000)  # Train for 10k steps\n",
        "end_gpu = time.time()\n",
        "gpu_time = end_gpu - start_gpu\n",
        "print(f\"⚡ GPU Training Time: {gpu_time:.2f} sec\")\n",
        "\n",
        "\n",
        "start_cpu = time.time()\n",
        "model_cpu = PPO(\"MlpPolicy\", env, device=\"cpu\", verbose=1)\n",
        "model_cpu.learn(1000)  # Train for 10k steps\n",
        "end_cpu = time.time()\n",
        "cpu_time = end_cpu - start_cpu\n",
        "print(f\"⚡ cpu Training Time: {cpu_time:.2f} sec\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w5y0_LbX0Zg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(curiosity_env.observation_space, curiosity_env.action_space)\n"
      ],
      "metadata": {
        "id": "5M39BJZD02lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stable_baselines3\n",
        "print(stable_baselines3.__version__)\n"
      ],
      "metadata": {
        "id": "v0GLsGAAE2H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogui"
      ],
      "metadata": {
        "id": "R4CPFGgaA9qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch torchvision torchaudio\n",
        "!pip install --upgrade stable-baselines3\n",
        "!pip cache purge\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "K4S2iAa1vjlp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}